{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/langchain-13-min/blob/main/notebooks/langchain-13-min.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "# import os\n",
        "\n",
        "# Contant for debug prints\n",
        "DEBUG = True     \n",
        "\n",
        "if load_dotenv(find_dotenv()):\n",
        "    print(\"Environment variables loaded successfully!\") if DEBUG else None\n",
        "    # print(os.getenv('OPENAI_API_KEY'))\n",
        "else:\n",
        "    print(\"Could not load environment variables.\") if DEBUG else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yrfYfKfdJyyF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings and vector databases are two key concepts in the field of natural language processing (NLP) and machine learning. They play a crucial role in representing textual data in a numerical format and enabling efficient similarity search operations.\n",
            "\n",
            "Embeddings can be defined as a technique of representing words, sentences, or documents as dense vectors in a high-dimensional space, typically with hundreds of dimensions. The goal of embeddings is to capture the semantic and syntactic relationships between words or documents, such that similar items are represented by vectors that are close to each other in the embedding space. This representation allows machines to understand and reason about textual data, which is otherwise challenging due to its unstructured nature.\n",
            "\n",
            "The process of generating embeddings involves two main steps: training and inference. During the training phase, a large corpus of text is fed into a neural network-based model, such as Word2Vec, GloVe, or BERT. The model learns to map words or sentences to their corresponding dense vectors by analyzing the co-occurrence patterns of words or using language modeling techniques. The training process aims to minimize the loss function, which measures the dissimilarity between the predicted context of a word and its actual context.\n",
            "\n",
            "Once the model is trained, the inference phase begins. During inference, new words or sentences are passed through the trained model, which maps them to their respective embeddings. These embeddings can then be used for various downstream tasks such as sentiment analysis, machine translation, question-answering systems, and information retrieval.\n",
            "\n",
            "On the other hand, vector databases are designed to efficiently store and retrieve embeddings for similarity search operations. A vector database, also known as an approximate nearest neighbor (ANN) index, organizes the embeddings in a data structure that enables fast retrieval of nearest neighbors based on some distance metric, such as cosine similarity or Euclidean distance.\n",
            "\n",
            "The key challenge in designing vector databases is to strike a balance between retrieval accuracy and computational efficiency. Traditional databases like SQL or NoSQL are not optimized for similarity search operations, as they primarily focus on storing and retrieving exact matches. In contrast, vector databases are specifically built to handle high-dimensional embeddings and approximate similarity search.\n",
            "\n",
            "One popular vector database is called Annoy (Approximate Nearest Neighbors Oh Yeah!), which is a lightweight C++ library that supports efficient retrieval of nearest neighbors. Annoy constructs a hierarchical tree structure (binary tree or k-d tree) to partition the embedding space and facilitate fast search operations. Another notable vector database is FAISS (Facebook AI Similarity Search), developed by Facebook AI Research. FAISS is highly optimized for large-scale similarity search and supports both CPU and GPU acceleration.\n",
            "\n",
            "To use a vector database, the first step is to populate it with the precomputed embeddings. Each embedding is associated with a unique identifier, such as a document ID or a word ID. Once the embeddings are stored, the vector database can be queried to retrieve the nearest neighbors for a given query embedding. The result is a ranked list of similar items based on their proximity in the embedding space.\n",
            "\n",
            "The relationship between embeddings and vector databases is that embeddings serve as the numerical representation of textual data, while vector databases provide the infrastructure for efficient similarity search operations on those embeddings. Embeddings capture the semantic meaning and relationships between words or documents, enabling machines to reason about textual data. Vector databases, on the other hand, store and index these embeddings to facilitate fast retrieval of nearest neighbors, enabling applications such as recommendation systems, content similarity detection, and search engines.\n",
            "\n",
            "In conclusion, embeddings and vector databases are essential components in NLP and machine learning. Embeddings provide a numerical representation of textual data, allowing machines to reason about words, sentences, or documents. Vector databases, on the other hand, provide the infrastructure for efficient similarity search operations on these embeddings. Together, they enable a wide range of applications that require understanding and manipulating textual data efficiently.\n"
          ]
        }
      ],
      "source": [
        "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\") # can also pass through temperatue\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert computer scientist and developer.\"),\n",
        "    HumanMessage(content=\"Explain the process of embeddings and vector databases, and their relationship in at least 500 words.\")\n",
        "]\n",
        "response=chat(messages)\n",
        "# chat(messages)\n",
        "print(response.content,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Embeddings and vector databases are two key concepts in the field of natural language processing (NLP) and machine learning. They play a crucial role in representing textual data in a numerical format and enabling efficient similarity search operations.\\n\\nEmbeddings can be defined as a technique of representing words, sentences, or documents as dense vectors in a high-dimensional space, typically with hundreds of dimensions. The goal of embeddings is to capture the semantic and syntactic relationships between words or documents, such that similar items are represented by vectors that are close to each other in the embedding space. This representation allows machines to understand and reason about textual data, which is otherwise challenging due to its unstructured nature.\\n\\nThe process of generating embeddings involves two main steps: training and inference. During the training phase, a large corpus of text is fed into a neural network-based model, such as Word2Vec, GloVe, or BERT. The model learns to map words or sentences to their corresponding dense vectors by analyzing the co-occurrence patterns of words or using language modeling techniques. The training process aims to minimize the loss function, which measures the dissimilarity between the predicted context of a word and its actual context.\\n\\nOnce the model is trained, the inference phase begins. During inference, new words or sentences are passed through the trained model, which maps them to their respective embeddings. These embeddings can then be used for various downstream tasks such as sentiment analysis, machine translation, question-answering systems, and information retrieval.\\n\\nOn the other hand, vector databases are designed to efficiently store and retrieve embeddings for similarity search operations. A vector database, also known as an approximate nearest neighbor (ANN) index, organizes the embeddings in a data structure that enables fast retrieval of nearest neighbors based on some distance metric, such as cosine similarity or Euclidean distance.\\n\\nThe key challenge in designing vector databases is to strike a balance between retrieval accuracy and computational efficiency. Traditional databases like SQL or NoSQL are not optimized for similarity search operations, as they primarily focus on storing and retrieving exact matches. In contrast, vector databases are specifically built to handle high-dimensional embeddings and approximate similarity search.\\n\\nOne popular vector database is called Annoy (Approximate Nearest Neighbors Oh Yeah!), which is a lightweight C++ library that supports efficient retrieval of nearest neighbors. Annoy constructs a hierarchical tree structure (binary tree or k-d tree) to partition the embedding space and facilitate fast search operations. Another notable vector database is FAISS (Facebook AI Similarity Search), developed by Facebook AI Research. FAISS is highly optimized for large-scale similarity search and supports both CPU and GPU acceleration.\\n\\nTo use a vector database, the first step is to populate it with the precomputed embeddings. Each embedding is associated with a unique identifier, such as a document ID or a word ID. Once the embeddings are stored, the vector database can be queried to retrieve the nearest neighbors for a given query embedding. The result is a ranked list of similar items based on their proximity in the embedding space.\\n\\nThe relationship between embeddings and vector databases is that embeddings serve as the numerical representation of textual data, while vector databases provide the infrastructure for efficient similarity search operations on those embeddings. Embeddings capture the semantic meaning and relationships between words or documents, enabling machines to reason about textual data. Vector databases, on the other hand, store and index these embeddings to facilitate fast retrieval of nearest neighbors, enabling applications such as recommendation systems, content similarity detection, and search engines.\\n\\nIn conclusion, embeddings and vector databases are essential components in NLP and machine learning. Embeddings provide a numerical representation of textual data, allowing machines to reason about words, sentences, or documents. Vector databases, on the other hand, provide the infrastructure for efficient similarity search operations on these embeddings. Together, they enable a wide range of applications that require understanding and manipulating textual data efficiently.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_str=response.content\n",
        "response_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mDDu1B_SLQls"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Embeddings and vector databases are two key concepts in the field of natural language processing', metadata={}),\n",
              " Document(page_content='(NLP) and machine learning. They play a crucial role in representing textual data in a numerical', metadata={}),\n",
              " Document(page_content='format and enabling efficient similarity search operations.', metadata={}),\n",
              " Document(page_content='Embeddings can be defined as a technique of representing words, sentences, or documents as dense', metadata={}),\n",
              " Document(page_content='vectors in a high-dimensional space, typically with hundreds of dimensions. The goal of embeddings', metadata={}),\n",
              " Document(page_content='is to capture the semantic and syntactic relationships between words or documents, such that similar', metadata={}),\n",
              " Document(page_content='items are represented by vectors that are close to each other in the embedding space. This', metadata={}),\n",
              " Document(page_content='representation allows machines to understand and reason about textual data, which is otherwise', metadata={}),\n",
              " Document(page_content='challenging due to its unstructured nature.', metadata={}),\n",
              " Document(page_content='The process of generating embeddings involves two main steps: training and inference. During the', metadata={}),\n",
              " Document(page_content='training phase, a large corpus of text is fed into a neural network-based model, such as Word2Vec,', metadata={}),\n",
              " Document(page_content='GloVe, or BERT. The model learns to map words or sentences to their corresponding dense vectors by', metadata={}),\n",
              " Document(page_content='analyzing the co-occurrence patterns of words or using language modeling techniques. The training', metadata={}),\n",
              " Document(page_content='process aims to minimize the loss function, which measures the dissimilarity between the predicted', metadata={}),\n",
              " Document(page_content='context of a word and its actual context.', metadata={}),\n",
              " Document(page_content='Once the model is trained, the inference phase begins. During inference, new words or sentences are', metadata={}),\n",
              " Document(page_content='passed through the trained model, which maps them to their respective embeddings. These embeddings', metadata={}),\n",
              " Document(page_content='can then be used for various downstream tasks such as sentiment analysis, machine translation,', metadata={}),\n",
              " Document(page_content='question-answering systems, and information retrieval.', metadata={}),\n",
              " Document(page_content='On the other hand, vector databases are designed to efficiently store and retrieve embeddings for', metadata={}),\n",
              " Document(page_content='similarity search operations. A vector database, also known as an approximate nearest neighbor (ANN)', metadata={}),\n",
              " Document(page_content='index, organizes the embeddings in a data structure that enables fast retrieval of nearest neighbors', metadata={}),\n",
              " Document(page_content='based on some distance metric, such as cosine similarity or Euclidean distance.', metadata={}),\n",
              " Document(page_content='The key challenge in designing vector databases is to strike a balance between retrieval accuracy', metadata={}),\n",
              " Document(page_content='and computational efficiency. Traditional databases like SQL or NoSQL are not optimized for', metadata={}),\n",
              " Document(page_content='similarity search operations, as they primarily focus on storing and retrieving exact matches. In', metadata={}),\n",
              " Document(page_content='contrast, vector databases are specifically built to handle high-dimensional embeddings and', metadata={}),\n",
              " Document(page_content='approximate similarity search.', metadata={}),\n",
              " Document(page_content='One popular vector database is called Annoy (Approximate Nearest Neighbors Oh Yeah!), which is a', metadata={}),\n",
              " Document(page_content='lightweight C++ library that supports efficient retrieval of nearest neighbors. Annoy constructs a', metadata={}),\n",
              " Document(page_content='hierarchical tree structure (binary tree or k-d tree) to partition the embedding space and', metadata={}),\n",
              " Document(page_content='facilitate fast search operations. Another notable vector database is FAISS (Facebook AI Similarity', metadata={}),\n",
              " Document(page_content='Search), developed by Facebook AI Research. FAISS is highly optimized for large-scale similarity', metadata={}),\n",
              " Document(page_content='search and supports both CPU and GPU acceleration.', metadata={}),\n",
              " Document(page_content='To use a vector database, the first step is to populate it with the precomputed embeddings. Each', metadata={}),\n",
              " Document(page_content='embedding is associated with a unique identifier, such as a document ID or a word ID. Once the', metadata={}),\n",
              " Document(page_content='embeddings are stored, the vector database can be queried to retrieve the nearest neighbors for a', metadata={}),\n",
              " Document(page_content='given query embedding. The result is a ranked list of similar items based on their proximity in the', metadata={}),\n",
              " Document(page_content='embedding space.', metadata={}),\n",
              " Document(page_content='The relationship between embeddings and vector databases is that embeddings serve as the numerical', metadata={}),\n",
              " Document(page_content='representation of textual data, while vector databases provide the infrastructure for efficient', metadata={}),\n",
              " Document(page_content='similarity search operations on those embeddings. Embeddings capture the semantic meaning and', metadata={}),\n",
              " Document(page_content='relationships between words or documents, enabling machines to reason about textual data. Vector', metadata={}),\n",
              " Document(page_content='databases, on the other hand, store and index these embeddings to facilitate fast retrieval of', metadata={}),\n",
              " Document(page_content='nearest neighbors, enabling applications such as recommendation systems, content similarity', metadata={}),\n",
              " Document(page_content='detection, and search engines.', metadata={}),\n",
              " Document(page_content='In conclusion, embeddings and vector databases are essential components in NLP and machine learning.', metadata={}),\n",
              " Document(page_content='Embeddings provide a numerical representation of textual data, allowing machines to reason about', metadata={}),\n",
              " Document(page_content='words, sentences, or documents. Vector databases, on the other hand, provide the infrastructure for', metadata={}),\n",
              " Document(page_content='efficient similarity search operations on these embeddings. Together, they enable a wide range of', metadata={}),\n",
              " Document(page_content='applications that require understanding and manipulating textual data efficiently.', metadata={})]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([response_str])\n",
        "texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F6lfAdeuLhtp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings and vector databases are two key concepts in the field of natural language processing\n",
            "(NLP) and machine learning. They play a crucial role in representing textual data in a numerical\n",
            "format and enabling efficient similarity search operations.\n",
            "Embeddings can be defined as a technique of representing words, sentences, or documents as dense\n",
            "vectors in a high-dimensional space, typically with hundreds of dimensions. The goal of embeddings\n",
            "is to capture the semantic and syntactic relationships between words or documents, such that similar\n",
            "items are represented by vectors that are close to each other in the embedding space. This\n",
            "representation allows machines to understand and reason about textual data, which is otherwise\n",
            "challenging due to its unstructured nature.\n",
            "The process of generating embeddings involves two main steps: training and inference. During the\n",
            "training phase, a large corpus of text is fed into a neural network-based model, such as Word2Vec,\n",
            "GloVe, or BERT. The model learns to map words or sentences to their corresponding dense vectors by\n",
            "analyzing the co-occurrence patterns of words or using language modeling techniques. The training\n",
            "process aims to minimize the loss function, which measures the dissimilarity between the predicted\n",
            "context of a word and its actual context.\n",
            "Once the model is trained, the inference phase begins. During inference, new words or sentences are\n",
            "passed through the trained model, which maps them to their respective embeddings. These embeddings\n",
            "can then be used for various downstream tasks such as sentiment analysis, machine translation,\n",
            "question-answering systems, and information retrieval.\n",
            "On the other hand, vector databases are designed to efficiently store and retrieve embeddings for\n",
            "similarity search operations. A vector database, also known as an approximate nearest neighbor (ANN)\n",
            "index, organizes the embeddings in a data structure that enables fast retrieval of nearest neighbors\n",
            "based on some distance metric, such as cosine similarity or Euclidean distance.\n",
            "The key challenge in designing vector databases is to strike a balance between retrieval accuracy\n",
            "and computational efficiency. Traditional databases like SQL or NoSQL are not optimized for\n",
            "similarity search operations, as they primarily focus on storing and retrieving exact matches. In\n",
            "contrast, vector databases are specifically built to handle high-dimensional embeddings and\n",
            "approximate similarity search.\n",
            "One popular vector database is called Annoy (Approximate Nearest Neighbors Oh Yeah!), which is a\n",
            "lightweight C++ library that supports efficient retrieval of nearest neighbors. Annoy constructs a\n",
            "hierarchical tree structure (binary tree or k-d tree) to partition the embedding space and\n",
            "facilitate fast search operations. Another notable vector database is FAISS (Facebook AI Similarity\n",
            "Search), developed by Facebook AI Research. FAISS is highly optimized for large-scale similarity\n",
            "search and supports both CPU and GPU acceleration.\n",
            "To use a vector database, the first step is to populate it with the precomputed embeddings. Each\n",
            "embedding is associated with a unique identifier, such as a document ID or a word ID. Once the\n",
            "embeddings are stored, the vector database can be queried to retrieve the nearest neighbors for a\n",
            "given query embedding. The result is a ranked list of similar items based on their proximity in the\n",
            "embedding space.\n",
            "The relationship between embeddings and vector databases is that embeddings serve as the numerical\n",
            "representation of textual data, while vector databases provide the infrastructure for efficient\n",
            "similarity search operations on those embeddings. Embeddings capture the semantic meaning and\n",
            "relationships between words or documents, enabling machines to reason about textual data. Vector\n",
            "databases, on the other hand, store and index these embeddings to facilitate fast retrieval of\n",
            "nearest neighbors, enabling applications such as recommendation systems, content similarity\n",
            "detection, and search engines.\n",
            "In conclusion, embeddings and vector databases are essential components in NLP and machine learning.\n",
            "Embeddings provide a numerical representation of textual data, allowing machines to reason about\n",
            "words, sentences, or documents. Vector databases, on the other hand, provide the infrastructure for\n",
            "efficient similarity search operations on these embeddings. Together, they enable a wide range of\n",
            "applications that require understanding and manipulating textual data efficiently.\n"
          ]
        }
      ],
      "source": [
        "# Individual text chunks can be accessed with \"page_content\"\n",
        "# texts[0].page_content\n",
        "for i in range(0, len(texts)):\n",
        "    print(texts[i].page_content)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Z5sv4e3tLw2y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', document_model_name='text-search-ada-doc-001', query_model_name='text-search-ada-query-001', embedding_ctx_length=8191, openai_api_key=None, openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import and instantiate OpenAI embeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings(model_name=\"ada\") \n",
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dqzoir4hMlfl"
      },
      "outputs": [],
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "# print(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QaOY5bIZM3Xz"
      },
      "outputs": [],
      "source": [
        "# Import and initialize Pinecone client\n",
        "import os\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.getenv('PINECONE_API_KEY'),  \n",
        "    environment=os.getenv('PINECONE_ENV')  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lZhSUt3FNBzN"
      },
      "outputs": [],
      "source": [
        "# Upload vectors to Pinecone\n",
        "index_name = \"learn-langchain\"\n",
        "search = Pinecone.from_documents(texts, embeddings, index_name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cCXVuXwPNKcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='context of a word and its actual context.', metadata={}),\n",
              " Document(page_content='detection, and search engines.', metadata={}),\n",
              " Document(page_content='approximate similarity search.', metadata={}),\n",
              " Document(page_content='embedding space.', metadata={})]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Do a simple vector similarity search\n",
        "query = \"What is the purpose of a vector?\"\n",
        "result = search.similarity_search(query)\n",
        "result"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
