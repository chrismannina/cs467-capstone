{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/langchain-13-min/blob/main/notebooks/langchain-13-min.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "# import os\n",
        "\n",
        "if load_dotenv(find_dotenv()):\n",
        "    print(\"Environment variables loaded successfully!\") \n",
        "    # print(os.getenv('OPENAI_API_KEY'))\n",
        "else:\n",
        "    print(\"Could not load environment variables.\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yrfYfKfdJyyF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector stores and embeddings can indeed be used to enhance ChatGPT's capabilities when dealing with medical documents it was never trained on. By leveraging these techniques, we can enable ChatGPT to understand and generate responses based on the content of medical documents from 2022.\n",
            "\n",
            "A vector store is a large collection of vectors, where each vector represents a piece of text or a document. These vectors are typically high-dimensional numerical representations that capture the semantic meaning of the corresponding text. Embeddings, on the other hand, are lower-dimensional representations of the original text, typically derived from vector stores using techniques like word2vec or BERT.\n",
            "\n",
            "To integrate vector stores and embeddings into ChatGPT, we can follow a two-step process: indexing and retrieval.\n",
            "\n",
            "In the indexing step, we process the medical documents from 2022 and convert them into vector representations using techniques like doc2vec or Universal Sentence Encoder. These vector representations capture the semantic information of the documents. These vectors are then stored in a vector store.\n",
            "\n",
            "In the retrieval step, when ChatGPT encounters a query related to medical information, it can use the same vectorization techniques to convert the query into a vector representation. This query vector is then compared with the vectors in the vector store to find the most relevant documents. This process is commonly known as nearest neighbor search.\n",
            "\n",
            "Once relevant documents are identified, ChatGPT can extract information from them to generate a response. This can be done by employing various natural language processing techniques such as named entity recognition, relationship extraction, or summarization. By leveraging these techniques, ChatGPT can effectively understand the content of medical documents and provide accurate responses.\n",
            "\n",
            "To further enhance the system, we can also incorporate fine-tuning techniques. After retrieving relevant documents, we can fine-tune ChatGPT using the retrieved documents and the corresponding queries to make it more contextually aware of the medical domain. This fine-tuning process can help the model generate more accurate and specific responses.\n",
            "\n",
            "Additionally, ChatGPT can also learn from user feedback. If the model generates incorrect or incomplete responses, users can provide corrective feedback. This feedback can be used to update the vector store and improve the relevance of future document retrieval.\n",
            "\n",
            "It's important to note that using vector stores and embeddings to enhance ChatGPT for medical documents from 2022 requires a continuous update of the vector store. As new medical documents become available, they need to be indexed and added to the vector store to ensure the system stays up-to-date.\n",
            "\n",
            "In conclusion, by leveraging vector stores and embeddings, ChatGPT can be enhanced to understand and generate responses based on medical documents it was never trained on from 2022. This can be achieved through indexing and retrieval techniques, as well as fine-tuning and user feedback. By continuously updating the vector store with new documents, ChatGPT can stay relevant and provide accurate information in the medical domain.\n"
          ]
        }
      ],
      "source": [
        "# import schema for chat messages and ChatOpenAI in order to query chatmodels GPT-3.5-turbo or GPT-4\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\") # can also pass through temperatue\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are an expert computer scientist and developer.\"),\n",
        "    HumanMessage(content=\"Explain how vector stores and embeddings can be used to enchance ChatGPT, so that we can input medical documents that it was never trained on from 2022 in at least 500 words.\")\n",
        "]\n",
        "response=chat(messages)\n",
        "# chat(messages)\n",
        "print(response.content,end='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Vector stores and embeddings can indeed be used to enhance ChatGPT's capabilities when dealing with medical documents it was never trained on. By leveraging these techniques, we can enable ChatGPT to understand and generate responses based on the content of medical documents from 2022.\\n\\nA vector store is a large collection of vectors, where each vector represents a piece of text or a document. These vectors are typically high-dimensional numerical representations that capture the semantic meaning of the corresponding text. Embeddings, on the other hand, are lower-dimensional representations of the original text, typically derived from vector stores using techniques like word2vec or BERT.\\n\\nTo integrate vector stores and embeddings into ChatGPT, we can follow a two-step process: indexing and retrieval.\\n\\nIn the indexing step, we process the medical documents from 2022 and convert them into vector representations using techniques like doc2vec or Universal Sentence Encoder. These vector representations capture the semantic information of the documents. These vectors are then stored in a vector store.\\n\\nIn the retrieval step, when ChatGPT encounters a query related to medical information, it can use the same vectorization techniques to convert the query into a vector representation. This query vector is then compared with the vectors in the vector store to find the most relevant documents. This process is commonly known as nearest neighbor search.\\n\\nOnce relevant documents are identified, ChatGPT can extract information from them to generate a response. This can be done by employing various natural language processing techniques such as named entity recognition, relationship extraction, or summarization. By leveraging these techniques, ChatGPT can effectively understand the content of medical documents and provide accurate responses.\\n\\nTo further enhance the system, we can also incorporate fine-tuning techniques. After retrieving relevant documents, we can fine-tune ChatGPT using the retrieved documents and the corresponding queries to make it more contextually aware of the medical domain. This fine-tuning process can help the model generate more accurate and specific responses.\\n\\nAdditionally, ChatGPT can also learn from user feedback. If the model generates incorrect or incomplete responses, users can provide corrective feedback. This feedback can be used to update the vector store and improve the relevance of future document retrieval.\\n\\nIt's important to note that using vector stores and embeddings to enhance ChatGPT for medical documents from 2022 requires a continuous update of the vector store. As new medical documents become available, they need to be indexed and added to the vector store to ensure the system stays up-to-date.\\n\\nIn conclusion, by leveraging vector stores and embeddings, ChatGPT can be enhanced to understand and generate responses based on medical documents it was never trained on from 2022. This can be achieved through indexing and retrieval techniques, as well as fine-tuning and user feedback. By continuously updating the vector store with new documents, ChatGPT can stay relevant and provide accurate information in the medical domain.\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_str=response.content\n",
        "response_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mDDu1B_SLQls"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"Vector stores and embeddings can indeed be used to enhance ChatGPT's capabilities when dealing with\", metadata={}),\n",
              " Document(page_content='medical documents it was never trained on. By leveraging these techniques, we can enable ChatGPT to', metadata={}),\n",
              " Document(page_content='understand and generate responses based on the content of medical documents from 2022.', metadata={}),\n",
              " Document(page_content='A vector store is a large collection of vectors, where each vector represents a piece of text or a', metadata={}),\n",
              " Document(page_content='document. These vectors are typically high-dimensional numerical representations that capture the', metadata={}),\n",
              " Document(page_content='semantic meaning of the corresponding text. Embeddings, on the other hand, are lower-dimensional', metadata={}),\n",
              " Document(page_content='representations of the original text, typically derived from vector stores using techniques like', metadata={}),\n",
              " Document(page_content='word2vec or BERT.', metadata={}),\n",
              " Document(page_content='To integrate vector stores and embeddings into ChatGPT, we can follow a two-step process: indexing', metadata={}),\n",
              " Document(page_content='and retrieval.', metadata={}),\n",
              " Document(page_content='In the indexing step, we process the medical documents from 2022 and convert them into vector', metadata={}),\n",
              " Document(page_content='representations using techniques like doc2vec or Universal Sentence Encoder. These vector', metadata={}),\n",
              " Document(page_content='representations capture the semantic information of the documents. These vectors are then stored in', metadata={}),\n",
              " Document(page_content='a vector store.', metadata={}),\n",
              " Document(page_content='In the retrieval step, when ChatGPT encounters a query related to medical information, it can use', metadata={}),\n",
              " Document(page_content='the same vectorization techniques to convert the query into a vector representation. This query', metadata={}),\n",
              " Document(page_content='vector is then compared with the vectors in the vector store to find the most relevant documents.', metadata={}),\n",
              " Document(page_content='This process is commonly known as nearest neighbor search.', metadata={}),\n",
              " Document(page_content='Once relevant documents are identified, ChatGPT can extract information from them to generate a', metadata={}),\n",
              " Document(page_content='response. This can be done by employing various natural language processing techniques such as', metadata={}),\n",
              " Document(page_content='named entity recognition, relationship extraction, or summarization. By leveraging these', metadata={}),\n",
              " Document(page_content='techniques, ChatGPT can effectively understand the content of medical documents and provide', metadata={}),\n",
              " Document(page_content='accurate responses.', metadata={}),\n",
              " Document(page_content='To further enhance the system, we can also incorporate fine-tuning techniques. After retrieving', metadata={}),\n",
              " Document(page_content='relevant documents, we can fine-tune ChatGPT using the retrieved documents and the corresponding', metadata={}),\n",
              " Document(page_content='queries to make it more contextually aware of the medical domain. This fine-tuning process can help', metadata={}),\n",
              " Document(page_content='the model generate more accurate and specific responses.', metadata={}),\n",
              " Document(page_content='Additionally, ChatGPT can also learn from user feedback. If the model generates incorrect or', metadata={}),\n",
              " Document(page_content='incomplete responses, users can provide corrective feedback. This feedback can be used to update', metadata={}),\n",
              " Document(page_content='the vector store and improve the relevance of future document retrieval.', metadata={}),\n",
              " Document(page_content=\"It's important to note that using vector stores and embeddings to enhance ChatGPT for medical\", metadata={}),\n",
              " Document(page_content='documents from 2022 requires a continuous update of the vector store. As new medical documents', metadata={}),\n",
              " Document(page_content='become available, they need to be indexed and added to the vector store to ensure the system stays', metadata={}),\n",
              " Document(page_content='up-to-date.', metadata={}),\n",
              " Document(page_content='In conclusion, by leveraging vector stores and embeddings, ChatGPT can be enhanced to understand', metadata={}),\n",
              " Document(page_content='and generate responses based on medical documents it was never trained on from 2022. This can be', metadata={}),\n",
              " Document(page_content='achieved through indexing and retrieval techniques, as well as fine-tuning and user feedback. By', metadata={}),\n",
              " Document(page_content='continuously updating the vector store with new documents, ChatGPT can stay relevant and provide', metadata={}),\n",
              " Document(page_content='accurate information in the medical domain.', metadata={})]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import utility for splitting up texts and split up the explanation given above into document chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=0,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([response_str])\n",
        "texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F6lfAdeuLhtp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings and vector databases are two important concepts in the field of natural language\n",
            "processing (NLP) and machine learning. They are closely related and play a crucial role in various\n",
            "applications such as information retrieval, recommendation systems, and semantic search. In this\n",
            "explanation, we will discuss the process of embeddings and vector databases and their relationship.\n",
            "1. Embeddings:\n",
            "Embeddings are vector representations of words, sentences, or documents in a high-dimensional\n",
            "space. The goal of embeddings is to capture the semantic and syntactic relationships between\n",
            "different entities in a way that is mathematically meaningful and computationally efficient.\n",
            "Embeddings are learned through a process called word embedding or sentence embedding.\n",
            "a. Word Embedding:\n",
            "Word embedding is the process of representing words as continuous vectors in a high-dimensional\n",
            "space. It is typically done using neural networks, specifically a technique called word2vec.\n",
            "Word2vec models learn word embeddings by training on large corpora of text data. The trained models\n",
            "capture the context and meaning of words by considering their surrounding words in the text. The\n",
            "resulting word embeddings can be used to measure semantic similarity, perform word analogy tasks,\n",
            "and support various NLP applications.\n",
            "b. Sentence Embedding:\n",
            "Sentence embedding is the process of representing sentences or documents as continuous vectors.\n",
            "Unlike word embeddings, sentence embeddings consider the entire context and meaning of a sentence\n",
            "rather than individual words. There are several techniques for sentence embedding, including\n",
            "averaging word embeddings, recurrent neural networks (RNNs), and transformers (such as BERT). These\n",
            "techniques capture the semantic relationships between sentences, enabling tasks like sentiment\n",
            "analysis, text classification, and information retrieval.\n",
            "2. Vector Databases:\n",
            "Vector databases, also known as similarity search databases, are specialized databases designed to\n",
            "efficiently store and query high-dimensional vectors. They are optimized for similarity search,\n",
            "which involves finding the most similar vectors to a given query vector. Vector databases use\n",
            "indexing structures and algorithms to organize and search the vectors effectively.\n",
            "a. Indexing Structures:\n",
            "Vector databases employ indexing structures such as k-d trees, ball trees, or random projection\n",
            "trees to partition the vector space. These structures divide the space into smaller regions,\n",
            "allowing for efficient search and retrieval of similar vectors. By organizing vectors in the index,\n",
            "vector databases can significantly speed up the similarity search process.\n",
            "b. Similarity Search Algorithms:\n",
            "Vector databases use similarity search algorithms to find the most similar vectors to a given query\n",
            "vector. These algorithms leverage the indexing structures to traverse the database efficiently and\n",
            "identify potential matches. Examples of similarity search algorithms include k-nearest neighbors\n",
            "(k-NN) search, approximate nearest neighbor (ANN) search, and locality-sensitive hashing (LSH).\n",
            "These algorithms trade off between accuracy and efficiency, providing different levels of\n",
            "approximation in the search process.\n",
            "3. Relationship between Embeddings and Vector Databases:\n",
            "Embeddings and vector databases are closely related in the sense that embeddings serve as the input\n",
            "data for vector databases. Embeddings capture the semantic relationships between words, sentences,\n",
            "or documents, while vector databases store and provide efficient search capabilities for these\n",
            "embeddings. The process of building a vector database typically involves the following steps:\n",
            "a. Embedding Generation:\n",
            "The first step is to generate embeddings for the entities of interest, such as words, sentences, or\n",
            "documents. This can be done using word embedding or sentence embedding techniques, as described\n",
            "earlier. The embeddings are then stored in a vector database.\n",
            "b. Indexing:\n",
            "The vector database organizes the embeddings using indexing structures to facilitate efficient\n",
            "search. The choice of indexing structure depends on the nature of the data and the desired\n",
            "trade-off between search time and memory usage.\n",
            "c. Querying:\n",
            "Once the vector database is built and indexed, it can be queried to find the most similar vectors\n",
            "to a given query vector. The query vector is typically an embedding of a word, sentence, or\n",
            "document that needs to be matched against the stored embeddings. The vector database employs\n",
            "similarity search algorithms to traverse the index and retrieve the most similar vectors.\n",
            "The relationship between embeddings and vector databases can be seen as a pipeline where embeddings\n",
            "are generated and then stored and queried using a vector database. This pipeline enables efficient\n",
            "retrieval of similar entities based on their semantic relationships, making it possible to build\n",
            "powerful applications such as semantic search engines, recommendation systems, and content-based\n",
            "filtering.\n",
            "In conclusion, embeddings and vector databases are essential components in the field of NLP and\n",
            "machine learning. Embeddings capture the semantic relationships between words, sentences, or\n",
            "documents, while vector databases provide efficient storage and retrieval mechanisms for these\n",
            "embeddings. Together, they enable advanced applications that require similarity search, content\n",
            "matching, and semantic analysis.\n"
          ]
        }
      ],
      "source": [
        "# Individual text chunks can be accessed with \"page_content\"\n",
        "# texts[0].page_content\n",
        "for i in range(0, len(texts)):\n",
        "    print(texts[i].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z5sv4e3tLw2y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base='', openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None, tiktoken_model_name=None, show_progress_bar=False)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import and instantiate OpenAI embeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings() \n",
        "embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dqzoir4hMlfl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.020228765904903412,\n",
              " 0.007087043486535549,\n",
              " 0.013748585246503353,\n",
              " -0.014494957402348518,\n",
              " -0.0008453357149846852,\n",
              " 0.01803847961127758,\n",
              " -0.0033795989584177732,\n",
              " -0.011076993308961391,\n",
              " -0.011893119663000107,\n",
              " -0.043470919132232666,\n",
              " -0.0033551850356161594,\n",
              " 0.05175773799419403,\n",
              " -0.015429665334522724,\n",
              " -0.01950332149863243,\n",
              " 0.020842604339122772,\n",
              " 0.01918245106935501,\n",
              " 0.006710370071232319,\n",
              " 0.023451417684555054,\n",
              " 0.01591794565320015,\n",
              " -0.03250553458929062,\n",
              " -0.01713167130947113,\n",
              " 0.020633341744542122,\n",
              " 0.005053703673183918,\n",
              " -0.010295744054019451,\n",
              " -0.014815826900303364,\n",
              " -0.0020019502844661474,\n",
              " 0.03381691500544548,\n",
              " -0.041461993008852005,\n",
              " -0.03214281052350998,\n",
              " -0.0014386838302016258,\n",
              " 0.012367448769509792,\n",
              " -0.01778736338019371,\n",
              " -0.03133366256952286,\n",
              " -0.04946979507803917,\n",
              " -0.03292405977845192,\n",
              " -0.00885182898491621,\n",
              " -0.004565423354506493,\n",
              " -0.027413465082645416,\n",
              " 0.029520047828555107,\n",
              " -0.00396204786375165,\n",
              " 0.03189169615507126,\n",
              " 0.00033547490602359176,\n",
              " -0.0030308272689580917,\n",
              " -0.03401222825050354,\n",
              " -0.0008928558672778308,\n",
              " 0.027901746332645416,\n",
              " -0.011725708842277527,\n",
              " -0.015415715053677559,\n",
              " -0.021135572344064713,\n",
              " 0.009981849230825901,\n",
              " 0.00202287663705647,\n",
              " 0.05424099415540695,\n",
              " -0.019907895475625992,\n",
              " 0.0008636462152935565,\n",
              " -0.00015934513066895306,\n",
              " -0.0018362837145105004,\n",
              " -0.003717907704412937,\n",
              " 0.0031738237012177706,\n",
              " 0.006284868344664574,\n",
              " 0.005873317364603281,\n",
              " 0.0019932310096919537,\n",
              " 0.022684119641780853,\n",
              " -0.007470692507922649,\n",
              " 0.01682475209236145,\n",
              " -0.042689669877290726,\n",
              " -0.0033325147815048695,\n",
              " -0.006581324152648449,\n",
              " 0.006668517366051674,\n",
              " 0.03828119486570358,\n",
              " -0.0006984155625104904,\n",
              " 0.010177161544561386,\n",
              " 0.01915454864501953,\n",
              " -0.006312770303338766,\n",
              " 0.008949484676122665,\n",
              " 0.01655968651175499,\n",
              " -0.029436342418193817,\n",
              " 0.026743823662400246,\n",
              " -0.021847067400813103,\n",
              " 0.0022373711690306664,\n",
              " 0.021386688575148582,\n",
              " 0.014250816777348518,\n",
              " -0.0363001711666584,\n",
              " -0.013755560852587223,\n",
              " 0.009033190086483955,\n",
              " 0.02001950331032276,\n",
              " 0.014222915284335613,\n",
              " 0.005329233594238758,\n",
              " 0.014760023914277554,\n",
              " 0.004872342571616173,\n",
              " 0.01589004509150982,\n",
              " 0.03431914746761322,\n",
              " 0.00901226419955492,\n",
              " 0.008370524272322655,\n",
              " 0.00831472035497427,\n",
              " 0.008426327258348465,\n",
              " 0.004443353042006493,\n",
              " -0.011725708842277527,\n",
              " -0.0006338927778415382,\n",
              " 0.01886158064007759,\n",
              " 0.003592349821701646,\n",
              " 0.0009085506317205727,\n",
              " 0.0067208330146968365,\n",
              " -0.039787888526916504,\n",
              " -0.013929946348071098,\n",
              " -0.022642267867922783,\n",
              " 0.0010899119079113007,\n",
              " 0.01563892886042595,\n",
              " -0.01579238846898079,\n",
              " -0.002865160582587123,\n",
              " 0.011258354410529137,\n",
              " -0.00845422875136137,\n",
              " 0.03465396910905838,\n",
              " 0.004910707473754883,\n",
              " -0.013839266262948513,\n",
              " -0.007435815408825874,\n",
              " -0.007118432782590389,\n",
              " 0.022209789603948593,\n",
              " -0.005807050969451666,\n",
              " -0.023311909288167953,\n",
              " -0.007589275017380714,\n",
              " 0.008830903097987175,\n",
              " 0.00954937282949686,\n",
              " 0.029352637007832527,\n",
              " -0.005869830027222633,\n",
              " 0.0018275643233209848,\n",
              " 0.027650630101561546,\n",
              " -0.022223740816116333,\n",
              " 0.006480180658400059,\n",
              " -0.011181624606251717,\n",
              " -0.027357662096619606,\n",
              " 0.010379449464380741,\n",
              " 0.010595687665045261,\n",
              " 0.025404540821909904,\n",
              " -0.006152335088700056,\n",
              " -0.0392298549413681,\n",
              " 0.01678290031850338,\n",
              " -0.0019600975792855024,\n",
              " -0.007568348664790392,\n",
              " -0.013134746812283993,\n",
              " -0.008656516671180725,\n",
              " -0.007048678584396839,\n",
              " 0.024790702387690544,\n",
              " -0.011851266957819462,\n",
              " -0.0009338365634903312,\n",
              " -0.0316963829100132,\n",
              " 0.020549636334180832,\n",
              " 0.022488808259367943,\n",
              " 0.020884456112980843,\n",
              " 0.01622486487030983,\n",
              " 0.002811101032420993,\n",
              " 0.006166285835206509,\n",
              " -0.022586463019251823,\n",
              " -0.007386987097561359,\n",
              " 0.011760585941374302,\n",
              " 0.0042166514322161674,\n",
              " -0.011955898255109787,\n",
              " 0.00476771080866456,\n",
              " -0.009988824836909771,\n",
              " -0.01629461906850338,\n",
              " -0.024316372349858284,\n",
              " 0.008293794468045235,\n",
              " 0.014829778112471104,\n",
              " -0.011572249233722687,\n",
              " 0.021219277754426003,\n",
              " 0.011544347740709782,\n",
              " 0.023646729066967964,\n",
              " -0.010288768447935581,\n",
              " 0.006068629678338766,\n",
              " 0.009814439341425896,\n",
              " -0.0016366117633879185,\n",
              " -0.01586214266717434,\n",
              " 0.022851530462503433,\n",
              " -0.023284006863832474,\n",
              " 0.024455880746245384,\n",
              " -0.005398987792432308,\n",
              " 0.0011823364766314626,\n",
              " 0.024623291566967964,\n",
              " -0.006462742108851671,\n",
              " -0.0004996156203560531,\n",
              " -0.027260005474090576,\n",
              " 0.012137259356677532,\n",
              " 0.0052734301425516605,\n",
              " 0.023772288113832474,\n",
              " 0.011474593542516232,\n",
              " 0.00947961863130331,\n",
              " -0.0051199705339968204,\n",
              " 0.025781214237213135,\n",
              " -0.021847067400813103,\n",
              " -0.005698931869119406,\n",
              " -0.030440805479884148,\n",
              " 0.01688055694103241,\n",
              " 0.006382524501532316,\n",
              " 0.011049091815948486,\n",
              " -0.03501669317483902,\n",
              " -0.6178562641143799,\n",
              " -0.01873602345585823,\n",
              " 0.025027865543961525,\n",
              " -0.004809563513845205,\n",
              " 0.008049653843045235,\n",
              " 0.005182749126106501,\n",
              " 0.0021013503428548574,\n",
              " 0.012200038880109787,\n",
              " -0.042187441140413284,\n",
              " 0.0315568745136261,\n",
              " -0.014704219996929169,\n",
              " 0.011823364533483982,\n",
              " -0.00984931644052267,\n",
              " -0.0018066380871459842,\n",
              " 0.015052991919219494,\n",
              " -0.002296662423759699,\n",
              " 0.0040910933166742325,\n",
              " -0.013483518734574318,\n",
              " 0.01957307569682598,\n",
              " 0.01883367821574211,\n",
              " -0.03124995529651642,\n",
              " 0.008823927491903305,\n",
              " -0.020772850140929222,\n",
              " -0.006358110345900059,\n",
              " 0.0013942153891548514,\n",
              " 0.012137259356677532,\n",
              " 0.00477468641474843,\n",
              " -0.008503057062625885,\n",
              " 0.01665734313428402,\n",
              " 0.020898407325148582,\n",
              " -0.03900664299726486,\n",
              " 0.0372767336666584,\n",
              " 0.029380539432168007,\n",
              " 0.0037737111561000347,\n",
              " 0.03264504298567772,\n",
              " 0.025167375802993774,\n",
              " -0.030329197645187378,\n",
              " 0.025292932987213135,\n",
              " 0.004893268924206495,\n",
              " 0.027915697544813156,\n",
              " -0.04958140477538109,\n",
              " -0.025962574407458305,\n",
              " 0.0005942200077697635,\n",
              " 0.012897581793367863,\n",
              " 0.0017830959986895323,\n",
              " 0.01907084323465824,\n",
              " 0.0007712217047810555,\n",
              " 0.004181774333119392,\n",
              " -0.01662944070994854,\n",
              " -0.012283743359148502,\n",
              " 0.007400938309729099,\n",
              " -0.0008069708128459752,\n",
              " 0.0036167637445032597,\n",
              " 0.008663492277264595,\n",
              " 0.025195276364684105,\n",
              " 0.0008680059108883142,\n",
              " 0.012255841866135597,\n",
              " -0.005873317364603281,\n",
              " 0.030022278428077698,\n",
              " -0.00048653670819476247,\n",
              " 0.030412903055548668,\n",
              " -0.010386425070464611,\n",
              " -0.03180798888206482,\n",
              " -0.0166154894977808,\n",
              " -0.023200301453471184,\n",
              " 0.025962574407458305,\n",
              " -0.0022792238742113113,\n",
              " 0.004568911157548428,\n",
              " -0.003318564034998417,\n",
              " -0.020075306296348572,\n",
              " 0.006267429795116186,\n",
              " 0.026953086256980896,\n",
              " -0.009270355105400085,\n",
              " 0.0010480593191459775,\n",
              " -0.00862163957208395,\n",
              " 0.03858811408281326,\n",
              " 0.010909582488238811,\n",
              " -0.008272867649793625,\n",
              " -0.022056329995393753,\n",
              " 0.010156235657632351,\n",
              " 0.012353498488664627,\n",
              " -0.010379449464380741,\n",
              " -0.023702533915638924,\n",
              " -0.0016052223509177566,\n",
              " 0.0012529627420008183,\n",
              " 0.0069614858366549015,\n",
              " -0.021428540349006653,\n",
              " -0.00786829274147749,\n",
              " 0.039341460913419724,\n",
              " -0.0013837522128596902,\n",
              " -0.005336208734661341,\n",
              " 0.03116624988615513,\n",
              " -0.03761155530810356,\n",
              " -0.03777896612882614,\n",
              " 0.007686931174248457,\n",
              " 0.0033168201334774494,\n",
              " -0.0028163325041532516,\n",
              " -0.006002363283187151,\n",
              " 0.001975792460143566,\n",
              " -0.00388531805947423,\n",
              " -0.007268405053764582,\n",
              " -0.01992184668779373,\n",
              " 0.01644807867705822,\n",
              " 0.011774537153542042,\n",
              " 0.025167375802993774,\n",
              " 0.03261714056134224,\n",
              " -0.015066943131387234,\n",
              " -0.000445991987362504,\n",
              " -0.003165104426443577,\n",
              " -0.0044154515489935875,\n",
              " -0.0015406995080411434,\n",
              " -0.003986462019383907,\n",
              " 0.013309133239090443,\n",
              " -0.044614892452955246,\n",
              " -0.007324208505451679,\n",
              " -0.03705351799726486,\n",
              " 0.042243242263793945,\n",
              " -0.020396176725625992,\n",
              " 0.021093720570206642,\n",
              " -0.03482137992978096,\n",
              " 0.01622486487030983,\n",
              " -0.008823927491903305,\n",
              " 0.011976824142038822,\n",
              " 0.0003261016681790352,\n",
              " 0.007373036351054907,\n",
              " 0.00824496615678072,\n",
              " 0.011628053151071072,\n",
              " -0.03565843030810356,\n",
              " 0.01608535647392273,\n",
              " 0.007247478701174259,\n",
              " 0.01717352494597435,\n",
              " -0.01601560227572918,\n",
              " 0.01919640228152275,\n",
              " -0.0038713673129677773,\n",
              " 0.031417366117239,\n",
              " 0.03878342732787132,\n",
              " 0.043080296367406845,\n",
              " 0.009898144751787186,\n",
              " -0.007603225763887167,\n",
              " -0.0038713673129677773,\n",
              " -0.01731303334236145,\n",
              " 0.010212038643658161,\n",
              " 0.021400639787316322,\n",
              " -0.0022094694431871176,\n",
              " -0.01714562252163887,\n",
              " -0.0189173836261034,\n",
              " -0.007366061210632324,\n",
              " 0.006127920933067799,\n",
              " -0.023130547255277634,\n",
              " -0.007903169840574265,\n",
              " 0.01937776245176792,\n",
              " -0.014550760388374329,\n",
              " -0.00870534498244524,\n",
              " 0.01668524369597435,\n",
              " 0.013518395833671093,\n",
              " -0.022098183631896973,\n",
              " -0.005845415871590376,\n",
              " -0.022558562457561493,\n",
              " -0.006944047287106514,\n",
              " -0.028878306970000267,\n",
              " -0.0076590292155742645,\n",
              " 0.022572511807084084,\n",
              " -0.005088580772280693,\n",
              " 0.017382787540555,\n",
              " -0.01016321126371622,\n",
              " -0.015318058431148529,\n",
              " -0.015429665334522724,\n",
              " 0.008754173293709755,\n",
              " -0.022823628038167953,\n",
              " -0.021721510216593742,\n",
              " 0.026269493624567986,\n",
              " -0.0395088717341423,\n",
              " 0.01577843725681305,\n",
              " 0.026129985228180885,\n",
              " -0.0367186963558197,\n",
              " 0.01812218502163887,\n",
              " -0.01702006533741951,\n",
              " 0.0066789803095161915,\n",
              " 0.024288469925522804,\n",
              " -0.0024431466590613127,\n",
              " 0.013434690423309803,\n",
              " 0.0005427761352621019,\n",
              " -0.026409002020955086,\n",
              " -0.005838440265506506,\n",
              " -0.0007350366213358939,\n",
              " -0.010832852683961391,\n",
              " 0.03498879075050354,\n",
              " 0.014941385015845299,\n",
              " -0.029129423201084137,\n",
              " -0.002450122032314539,\n",
              " 0.019991600885987282,\n",
              " 0.026353199034929276,\n",
              " -0.014139209873974323,\n",
              " 0.022488808259367943,\n",
              " -0.001930452068336308,\n",
              " 0.0003729678865056485,\n",
              " -0.0021397152449935675,\n",
              " 0.014718171209096909,\n",
              " -0.012583687901496887,\n",
              " 0.0003053933323826641,\n",
              " 0.012486031278967857,\n",
              " -0.00824496615678072,\n",
              " 0.006218601483851671,\n",
              " -0.01918245106935501,\n",
              " 0.030747724696993828,\n",
              " -0.011000263504683971,\n",
              " 0.0040910933166742325,\n",
              " -0.029408439993858337,\n",
              " 0.024748848751187325,\n",
              " 0.026994939893484116,\n",
              " 0.0035086446441709995,\n",
              " 0.0016409714007750154,\n",
              " -0.027818040922284126,\n",
              " 0.020870506763458252,\n",
              " 0.00786829274147749,\n",
              " 0.03736043721437454,\n",
              " -0.007421864662319422,\n",
              " 0.005988412071019411,\n",
              " -0.0016557942144572735,\n",
              " -0.004875830374658108,\n",
              " 0.0020403151866048574,\n",
              " -0.01841515302658081,\n",
              " 0.025320835411548615,\n",
              " 0.006623176857829094,\n",
              " -0.010505007579922676,\n",
              " 0.03272874653339386,\n",
              " -0.0067626857198774815,\n",
              " 0.011530396528542042,\n",
              " -0.010372473858296871,\n",
              " -0.004684005863964558,\n",
              " 0.014857679605484009,\n",
              " 0.0020682169124484062,\n",
              " 0.010658467188477516,\n",
              " -0.009207576513290405,\n",
              " 0.008279843255877495,\n",
              " -0.020730996504426003,\n",
              " 0.044112659990787506,\n",
              " -0.0050781178288161755,\n",
              " 0.03819749131798744,\n",
              " 0.0011989031918346882,\n",
              " -0.001991487108170986,\n",
              " 0.01735488697886467,\n",
              " -0.007903169840574265,\n",
              " -0.025265030562877655,\n",
              " 0.01771760918200016,\n",
              " 0.012165161781013012,\n",
              " 0.012534859590232372,\n",
              " -0.006508082151412964,\n",
              " -0.020535685122013092,\n",
              " -0.005639640614390373,\n",
              " -0.012695294804871082,\n",
              " -0.00993999745696783,\n",
              " -0.022265592589974403,\n",
              " 0.00457588629797101,\n",
              " 0.01636437326669693,\n",
              " 0.0032889184076339006,\n",
              " 0.03789057210087776,\n",
              " 0.014257792383432388,\n",
              " 0.014648417010903358,\n",
              " 0.028738798573613167,\n",
              " -0.009026214480400085,\n",
              " -0.0033360025845468044,\n",
              " -0.004080630373209715,\n",
              " 0.0022094694431871176,\n",
              " 0.01914059743285179,\n",
              " -0.026646167039871216,\n",
              " 0.002403037855401635,\n",
              " -0.021665705367922783,\n",
              " -0.03348209708929062,\n",
              " 0.011216501705348492,\n",
              " 0.0060616545379161835,\n",
              " -0.014662367291748524,\n",
              " -0.014494957402348518,\n",
              " -0.01884762942790985,\n",
              " -0.012032628059387207,\n",
              " -0.004534033592790365,\n",
              " -0.0014299644390121102,\n",
              " 0.01662944070994854,\n",
              " -0.004666566848754883,\n",
              " 0.021037915721535683,\n",
              " 0.0015755767235532403,\n",
              " -0.05736599117517471,\n",
              " -0.0004926401888951659,\n",
              " 0.002296662423759699,\n",
              " -0.028403976932168007,\n",
              " -0.006249991245567799,\n",
              " -0.03356580063700676,\n",
              " 0.010337596759200096,\n",
              " -0.020661242306232452,\n",
              " 0.00412248307839036,\n",
              " 0.00484444061294198,\n",
              " 0.013616052456200123,\n",
              " 0.000202832612558268,\n",
              " -0.010951435193419456,\n",
              " 0.009033190086483955,\n",
              " 0.0201729629188776,\n",
              " 0.022391151636838913,\n",
              " -0.020633341744542122,\n",
              " -0.0014674575068056583,\n",
              " 0.015066943131387234,\n",
              " 0.023632779717445374,\n",
              " 0.009751660749316216,\n",
              " -0.029464244842529297,\n",
              " -0.015373862348496914,\n",
              " 0.03554682433605194,\n",
              " -0.012276768684387207,\n",
              " -0.023437466472387314,\n",
              " 0.0009015752002596855,\n",
              " -0.013860192149877548,\n",
              " -0.011697807349264622,\n",
              " 0.010930509306490421,\n",
              " -0.004670054651796818,\n",
              " -0.027246054261922836,\n",
              " -0.0016985187539830804,\n",
              " 0.020465930923819542,\n",
              " 0.012862704694271088,\n",
              " -0.015611027367413044,\n",
              " -0.004952560178935528,\n",
              " 0.022935235872864723,\n",
              " 0.01711772195994854,\n",
              " -0.006173261441290379,\n",
              " -0.03264504298567772,\n",
              " -0.012562761083245277,\n",
              " 0.005364110693335533,\n",
              " 0.027385564520955086,\n",
              " 0.014467054978013039,\n",
              " -0.013183575123548508,\n",
              " -0.007010313682258129,\n",
              " -0.01586214266717434,\n",
              " -0.01947541907429695,\n",
              " -0.020842604339122772,\n",
              " -0.013811364769935608,\n",
              " 0.004042265471071005,\n",
              " -0.004561935551464558,\n",
              " -0.01706191711127758,\n",
              " -0.0038818304892629385,\n",
              " 0.026520609855651855,\n",
              " 0.006253479048609734,\n",
              " 0.0014796644682064652,\n",
              " 0.025432441383600235,\n",
              " -0.030217591673135757,\n",
              " -0.03708142042160034,\n",
              " -0.0008597225532867014,\n",
              " 0.0004464279336389154,\n",
              " 0.01718747615814209,\n",
              " 0.002708213170990348,\n",
              " 0.0036969813518226147,\n",
              " 0.01972653530538082,\n",
              " 0.015136697329580784,\n",
              " -0.009877217933535576,\n",
              " 0.01715957373380661,\n",
              " 0.014020627364516258,\n",
              " -0.01711772195994854,\n",
              " -0.05499434098601341,\n",
              " -0.03906244412064552,\n",
              " 0.025153424590826035,\n",
              " -0.011802438646554947,\n",
              " -0.003798125311732292,\n",
              " -0.03124995529651642,\n",
              " 0.03635597601532936,\n",
              " -0.004516595043241978,\n",
              " 0.006588299758732319,\n",
              " 0.007261429447680712,\n",
              " 0.0008261532639153302,\n",
              " 0.012646466493606567,\n",
              " 0.01017018686980009,\n",
              " 0.012262817472219467,\n",
              " -0.0025756799150258303,\n",
              " -0.005775661673396826,\n",
              " -0.01932195946574211,\n",
              " 0.0169642623513937,\n",
              " -0.01565288007259369,\n",
              " -0.013302157633006573,\n",
              " -0.0004246296884957701,\n",
              " 0.026953086256980896,\n",
              " 0.012911533005535603,\n",
              " -0.01650388352572918,\n",
              " 0.014013651758432388,\n",
              " 0.01902899146080017,\n",
              " 0.0014482750557363033,\n",
              " -0.0021240203641355038,\n",
              " 0.01833144761621952,\n",
              " -0.011948922649025917,\n",
              " -0.020131109282374382,\n",
              " -0.022837579250335693,\n",
              " -0.005095556378364563,\n",
              " 0.000707570870872587,\n",
              " -0.029520047828555107,\n",
              " -0.0016706170281395316,\n",
              " -0.013783462345600128,\n",
              " 0.005060679279267788,\n",
              " -0.013748585246503353,\n",
              " -0.014801876619458199,\n",
              " 0.0010777049465104938,\n",
              " -0.01983814127743244,\n",
              " -0.013964824378490448,\n",
              " -0.03094303607940674,\n",
              " -0.013344010338187218,\n",
              " 0.027343710884451866,\n",
              " 0.00870534498244524,\n",
              " 0.01683870330452919,\n",
              " -0.008656516671180725,\n",
              " -0.014885582029819489,\n",
              " 0.020926309749484062,\n",
              " 0.005653591360896826,\n",
              " -0.01808033138513565,\n",
              " 0.010365498252213001,\n",
              " -0.0032366025261580944,\n",
              " -0.029882770031690598,\n",
              " 0.023074744269251823,\n",
              " 0.00019400432938709855,\n",
              " -0.005493156146258116,\n",
              " -0.011983799748122692,\n",
              " -0.01946146786212921,\n",
              " -0.002242602873593569,\n",
              " -0.023270055651664734,\n",
              " 0.008049653843045235,\n",
              " -0.00481305131688714,\n",
              " 0.0175222959369421,\n",
              " 0.023311909288167953,\n",
              " 0.013134746812283993,\n",
              " -0.0021222764626145363,\n",
              " 0.014690269716084003,\n",
              " -0.0379742756485939,\n",
              " -0.015415715053677559,\n",
              " 0.0001324243057752028,\n",
              " 0.0053536477498710155,\n",
              " -0.023632779717445374,\n",
              " 0.013295182026922703,\n",
              " 0.003986462019383907,\n",
              " -0.006745247170329094,\n",
              " 0.015108795836567879,\n",
              " -0.0049979002214968204,\n",
              " -0.013323083519935608,\n",
              " 0.009835365228354931,\n",
              " -0.011300207115709782,\n",
              " 0.00868441816419363,\n",
              " -0.0169642623513937,\n",
              " 0.0015834240475669503,\n",
              " 0.006832439918071032,\n",
              " 0.00899831298738718,\n",
              " 0.021707559004426003,\n",
              " -0.002090887166559696,\n",
              " -0.03186379373073578,\n",
              " -0.021191375330090523,\n",
              " -0.01618301309645176,\n",
              " 0.0200334545224905,\n",
              " -0.0026245079934597015,\n",
              " -0.0032749674282968044,\n",
              " 0.01547151803970337,\n",
              " 0.008028727024793625,\n",
              " 0.005831465125083923,\n",
              " -0.0315568745136261,\n",
              " -0.0006003234884701669,\n",
              " -0.028222616761922836,\n",
              " 0.022977087646722794,\n",
              " -0.011655954644083977,\n",
              " 0.0026750799734145403,\n",
              " -0.025320835411548615,\n",
              " -0.0034755112137645483,\n",
              " -0.0322544202208519,\n",
              " 0.012967336922883987,\n",
              " -0.020605439320206642,\n",
              " 0.007345134858042002,\n",
              " -0.0012695294572040439,\n",
              " 0.0067243208177387714,\n",
              " -0.009193625301122665,\n",
              " -0.0364396795630455,\n",
              " 0.001303534721955657,\n",
              " -0.043526723980903625,\n",
              " -0.024093158543109894,\n",
              " 0.0376952588558197,\n",
              " 0.03362160548567772,\n",
              " 0.04595417529344559,\n",
              " -0.012534859590232372,\n",
              " 0.014299645088613033,\n",
              " -0.012137259356677532,\n",
              " -0.027720384299755096,\n",
              " -0.007303282152861357,\n",
              " -0.0195451732724905,\n",
              " 0.005611738655716181,\n",
              " 0.01635042391717434,\n",
              " 0.025418490171432495,\n",
              " -0.0013427715748548508,\n",
              " 0.03738833963871002,\n",
              " -0.009835365228354931,\n",
              " 0.03208700940012932,\n",
              " -0.01573658548295498,\n",
              " 0.000703647150658071,\n",
              " 0.001426476752385497,\n",
              " 0.0068359277211129665,\n",
              " -0.0158481914550066,\n",
              " -0.012213989160954952,\n",
              " -0.0006500235176645219,\n",
              " 0.009116895496845245,\n",
              " -0.00932615902274847,\n",
              " 0.011746634729206562,\n",
              " -0.01736883632838726,\n",
              " 0.01947541907429695,\n",
              " 0.013316107913851738,\n",
              " -0.008265892043709755,\n",
              " -0.014146185480058193,\n",
              " -0.027580875903367996,\n",
              " -0.03543521836400032,\n",
              " -0.03858811408281326,\n",
              " 0.026506658643484116,\n",
              " 0.001388111850246787,\n",
              " 0.007442791014909744,\n",
              " -0.03250553458929062,\n",
              " 0.003299381583929062,\n",
              " 0.0019095257157459855,\n",
              " 0.020744947716593742,\n",
              " -0.0012599382316693664,\n",
              " 0.01964282989501953,\n",
              " 0.03886713087558746,\n",
              " 0.0007734015234746039,\n",
              " -0.011690831743180752,\n",
              " -0.005737296771258116,\n",
              " -0.01937776245176792,\n",
              " -0.013469567522406578,\n",
              " 0.00909596960991621,\n",
              " -0.03696981444954872,\n",
              " -0.0014447872526943684,\n",
              " 0.01594584807753563,\n",
              " 0.01795477420091629,\n",
              " 0.011397863738238811,\n",
              " 0.011676880531013012,\n",
              " 0.0025006940122693777,\n",
              " -0.004003900568932295,\n",
              " 0.021219277754426003,\n",
              " -0.03744414448738098,\n",
              " -0.009877217933535576,\n",
              " -0.0037004691548645496,\n",
              " -0.029910672456026077,\n",
              " -0.0351841002702713,\n",
              " 0.00013111640873830765,\n",
              " -0.03493298590183258,\n",
              " -0.015332009643316269,\n",
              " 0.010770074091851711,\n",
              " 0.014397300779819489,\n",
              " -0.007013801485300064,\n",
              " 0.043163999915122986,\n",
              " -0.03217071294784546,\n",
              " -0.028083108365535736,\n",
              " 5.220678212936036e-05,\n",
              " 0.0030308272689580917,\n",
              " 0.011690831743180752,\n",
              " 0.0009469155338592827,\n",
              " -0.0006099147140048444,\n",
              " -0.0002718240430112928,\n",
              " 0.00847515556961298,\n",
              " -0.011286255903542042,\n",
              " 0.011321133933961391,\n",
              " 0.025948623195290565,\n",
              " 0.00111519789788872,\n",
              " -0.0029488657601177692,\n",
              " 0.038113784044981,\n",
              " -0.01946146786212921,\n",
              " -0.025125522166490555,\n",
              " 0.01923825405538082,\n",
              " 0.010072530247271061,\n",
              " -0.00807755533605814,\n",
              " -0.044280070811510086,\n",
              " 0.013448641635477543,\n",
              " 0.01612721011042595,\n",
              " 0.008803000673651695,\n",
              " -0.010225989855825901,\n",
              " -0.01909874565899372,\n",
              " -0.024665143340826035,\n",
              " 0.013316107913851738,\n",
              " -0.012806901708245277,\n",
              " 0.004924658220261335,\n",
              " 0.011251378804445267,\n",
              " -0.009507520124316216,\n",
              " -0.020438028499484062,\n",
              " 0.03482137992978096,\n",
              " -0.024818602949380875,\n",
              " 0.031417366117239,\n",
              " -0.003941121511161327,\n",
              " 0.027720384299755096,\n",
              " -0.0189173836261034,\n",
              " 0.010030677542090416,\n",
              " 0.011439715512096882,\n",
              " 0.013016164302825928,\n",
              " -0.003937633708119392,\n",
              " 0.01658758893609047,\n",
              " -0.0157086830586195,\n",
              " 0.00042244986980222166,\n",
              " 0.0016897994792088866,\n",
              " 0.0011683856137096882,\n",
              " -0.0020629854407161474,\n",
              " -0.0161969643086195,\n",
              " -0.0026785675436258316,\n",
              " 0.03604905679821968,\n",
              " -0.030691921710968018,\n",
              " -0.012695294804871082,\n",
              " 0.03900664299726486,\n",
              " 0.015136697329580784,\n",
              " 0.028306322172284126,\n",
              " -0.014676318503916264,\n",
              " -0.008579786866903305,\n",
              " -0.006288356147706509,\n",
              " -0.020284568890929222,\n",
              " -0.023242155089974403,\n",
              " 0.029157325625419617,\n",
              " 0.002804125426337123,\n",
              " 0.020061355084180832,\n",
              " 0.006699906662106514,\n",
              " -0.006044215988367796,\n",
              " -0.01916849985718727,\n",
              " -0.01803847961127758,\n",
              " -0.009514495730400085,\n",
              " 0.021944724023342133,\n",
              " -0.01685265451669693,\n",
              " -0.022153986617922783,\n",
              " 0.00012163417704869062,\n",
              " 0.011425765231251717,\n",
              " 0.010407350957393646,\n",
              " -0.01589004509150982,\n",
              " -0.03540731593966484,\n",
              " 0.020619390532374382,\n",
              " 0.07215391844511032,\n",
              " 0.003172079799696803,\n",
              " 0.01855466142296791,\n",
              " -0.0006225577089935541,\n",
              " -0.0008200497832149267,\n",
              " -0.040290120989084244,\n",
              " -0.0031738237012177706,\n",
              " -0.005057191476225853,\n",
              " -0.011111870408058167,\n",
              " 0.006790587678551674,\n",
              " -0.014606564305722713,\n",
              " -0.024260567501187325,\n",
              " -0.030050180852413177,\n",
              " -0.00807755533605814,\n",
              " 0.041294585913419724,\n",
              " -0.004363135434687138,\n",
              " 0.0038016128819435835,\n",
              " 0.010491056367754936,\n",
              " -0.0009338365634903312,\n",
              " 0.015443616546690464,\n",
              " -0.01695031113922596,\n",
              " -0.022084232419729233,\n",
              " 0.0028320271521806717,\n",
              " -0.011446691118180752,\n",
              " -0.0086913937702775,\n",
              " 0.03342629224061966,\n",
              " -0.0617186613380909,\n",
              " -0.006113970186561346,\n",
              " 0.004854904022067785,\n",
              " 0.03398432582616806,\n",
              " 0.008893681690096855,\n",
              " -0.012402325868606567,\n",
              " -0.03191959857940674,\n",
              " -0.01722932793200016,\n",
              " -0.022014478221535683,\n",
              " -0.025181325152516365,\n",
              " -0.01742464117705822,\n",
              " -0.006455766502767801,\n",
              " -0.007191675249487162,\n",
              " -0.01824774220585823,\n",
              " 0.008426327258348465,\n",
              " 0.01784316636621952,\n",
              " -0.01635042391717434,\n",
              " 0.002335027325898409,\n",
              " 0.027539024129509926,\n",
              " 0.01576448604464531,\n",
              " 0.0004503516247496009,\n",
              " -0.004565423354506493,\n",
              " -0.006365085951983929,\n",
              " -0.021665705367922783,\n",
              " -0.005531521048396826,\n",
              " -0.022098183631896973,\n",
              " 0.011356011033058167,\n",
              " 0.012416277080774307,\n",
              " 0.039174050092697144,\n",
              " 0.01554127223789692,\n",
              " -0.01563892886042595,\n",
              " -0.022767825052142143,\n",
              " -0.0023908307775855064,\n",
              " -0.027622729539871216,\n",
              " -0.024553537368774414,\n",
              " -0.004436377435922623,\n",
              " -0.003372623585164547,\n",
              " 0.0005972717772237957,\n",
              " 0.04581466689705849,\n",
              " -0.015066943131387234,\n",
              " 0.024441929534077644,\n",
              " 0.011383912526071072,\n",
              " 0.028794601559638977,\n",
              " -0.020312471315264702,\n",
              " 0.021261131390929222,\n",
              " -0.020479882135987282,\n",
              " -0.021623853594064713,\n",
              " 0.024079207330942154,\n",
              " 0.007317232899367809,\n",
              " -0.026813577860593796,\n",
              " -0.006194187793880701,\n",
              " 0.002804125426337123,\n",
              " 0.006452278699725866,\n",
              " 0.0077497102320194244,\n",
              " 0.007069604936987162,\n",
              " 0.015066943131387234,\n",
              " 0.010239941067993641,\n",
              " -0.021358786150813103,\n",
              " -0.012416277080774307,\n",
              " 0.01750834658741951,\n",
              " 0.0004261555732227862,\n",
              " 0.0312778577208519,\n",
              " -0.026102082803845406,\n",
              " -0.004551472142338753,\n",
              " 0.023493269458413124,\n",
              " -0.007261429447680712,\n",
              " -0.023102646693587303,\n",
              " 0.005343184340745211,\n",
              " 0.0005876805516891181,\n",
              " 0.013915996067225933,\n",
              " -0.0006007594638504088,\n",
              " -0.022237692028284073,\n",
              " 0.004387549590319395,\n",
              " -0.012102382257580757,\n",
              " -0.010156235657632351,\n",
              " 0.03864391893148422,\n",
              " 0.021540148183703423,\n",
              " -0.0031319709960371256,\n",
              " 0.022670168429613113,\n",
              " 0.007875267416238785,\n",
              " 0.026883332058787346,\n",
              " -0.006002363283187151,\n",
              " 0.007686931174248457,\n",
              " 0.015178550034761429,\n",
              " 0.00808453094214201,\n",
              " 0.01577843725681305,\n",
              " -0.01731303334236145,\n",
              " -0.0026384589727967978,\n",
              " -0.025446392595767975,\n",
              " 0.012032628059387207,\n",
              " -0.022223740816116333,\n",
              " -0.014111308380961418,\n",
              " -0.00400738837197423,\n",
              " -0.00229143095202744,\n",
              " -0.01695031113922596,\n",
              " 0.022823628038167953,\n",
              " 0.0036481532733887434,\n",
              " -0.044196367263793945,\n",
              " 0.011272305622696877,\n",
              " -0.005737296771258116,\n",
              " 0.0005279533797875047,\n",
              " -0.030329197645187378,\n",
              " -0.008593738079071045,\n",
              " -0.014222915284335613,\n",
              " -0.007672980427742004,\n",
              " 0.0021780801471322775,\n",
              " 0.01904294267296791,\n",
              " -0.00853095855563879,\n",
              " -0.0026384589727967978,\n",
              " 0.01799662597477436,\n",
              " -0.007798538077622652,\n",
              " -0.029464244842529297,\n",
              " 0.00870534498244524,\n",
              " 0.16584797203540802,\n",
              " -0.015122746117413044,\n",
              " -0.0023559536784887314,\n",
              " 0.028501633554697037,\n",
              " 0.009333133697509766,\n",
              " -0.012437202967703342,\n",
              " 0.01821983978152275,\n",
              " -0.004031802527606487,\n",
              " -0.005988412071019411,\n",
              " 0.0015790644101798534,\n",
              " 0.024023404344916344,\n",
              " -0.00906806718558073,\n",
              " -0.03897874057292938,\n",
              " 0.008523983880877495,\n",
              " 0.021065818145871162,\n",
              " -0.023855993524193764,\n",
              " -0.03412383422255516,\n",
              " -0.04422426596283913,\n",
              " -0.010825877077877522,\n",
              " 0.012779000215232372,\n",
              " 0.005325745791196823,\n",
              " -0.0011492031626403332,\n",
              " -0.0018310521263629198,\n",
              " -0.03789057210087776,\n",
              " 0.008572811260819435,\n",
              " -0.0036132761742919683,\n",
              " 0.004028314724564552,\n",
              " -0.0069579980336129665,\n",
              " -0.009423814713954926,\n",
              " 0.012130283750593662,\n",
              " -0.0023629290517419577,\n",
              " -0.022014478221535683,\n",
              " 0.0010515470057725906,\n",
              " -0.014215939678251743,\n",
              " 0.022084232419729233,\n",
              " -0.005883780773729086,\n",
              " 0.01816403679549694,\n",
              " -0.004401500336825848,\n",
              " 0.0075404467061161995,\n",
              " 0.006424377206712961,\n",
              " 0.007296306546777487,\n",
              " 0.012234915979206562,\n",
              " -0.0016924153314903378,\n",
              " -0.01637832447886467,\n",
              " 0.006406938657164574,\n",
              " 0.01972653530538082,\n",
              " ...]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn the first text chunk into a vector with the embedding\n",
        "query_result = embeddings.embed_query(texts[0].page_content)\n",
        "query_result\n",
        "\n",
        "# todo: avail functions for OpenAIEmbeddings? should this be embed_query, or document/search, etc. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QaOY5bIZM3Xz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chrismannina/cs-projects/school/cs467-capstone/myenv/lib/python3.11/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "# Import and initialize Pinecone client\n",
        "import os\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.getenv('PINECONE_API_KEY'),  \n",
        "    environment=os.getenv('PINECONE_ENV')  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lZhSUt3FNBzN"
      },
      "outputs": [],
      "source": [
        "# Upload vectors to Pinecone\n",
        "index_name = \"file-q-and-a\"\n",
        "search = Pinecone.from_documents(texts, embeddings, index_name=index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cCXVuXwPNKcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='a vector store.', metadata={}),\n",
              " Document(page_content='The main purpose of a vector database is to store the embeddings generated from the previous step', metadata={}),\n",
              " Document(page_content='the vector store and improve the relevance of future document retrieval.', metadata={}),\n",
              " Document(page_content='vector is then compared with the vectors in the vector store to find the most relevant documents.', metadata={})]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Do a simple vector similarity search\n",
        "query = \"What is the purpose of a vector?\"\n",
        "result = search.similarity_search(query)\n",
        "result"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
